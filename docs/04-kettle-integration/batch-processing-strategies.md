---
## ğŸ“– å¯¼èˆª
[ğŸ  è¿”å›ä¸»é¡µ](../../README.md) | [â¬…ï¸ ä¸Šä¸€é¡µ](modern-etl-tools.md) | [â¡ï¸ ä¸‹ä¸€é¡µ](error-handling-mechanisms.md)
---

# æ‰¹é‡å¤„ç†ç­–ç•¥

æœ¬ç« èŠ‚ä»‹ç»åœ¨ Kettle/PDI ä¸­å®ç° StarRocks æ‰¹é‡æ•°æ®å¤„ç†çš„ç­–ç•¥å’Œæœ€ä½³å®è·µï¼ŒåŒ…æ‹¬åˆ†ç‰‡ç­–ç•¥ã€å¹¶è¡Œå¤„ç†ã€èµ„æºç®¡ç†å’Œæ€§èƒ½è°ƒä¼˜ç­‰å…³é”®æŠ€æœ¯ã€‚

## 1. æ‰¹é‡å¤„ç†æ¶æ„è®¾è®¡

### 1.1 å¤„ç†æ¶æ„æ¦‚è§ˆ

```
æ•°æ®æº (Source Database)
    â†“
æ•°æ®åˆ†ç‰‡ (Data Sharding)
    â†“
å¹¶è¡Œå¤„ç† (Parallel Processing)
    â”œâ”€â”€ Worker 1 â†’ StarRocks Partition 1
    â”œâ”€â”€ Worker 2 â†’ StarRocks Partition 2  
    â”œâ”€â”€ Worker 3 â†’ StarRocks Partition 3
    â””â”€â”€ Worker N â†’ StarRocks Partition N
    â†“
ç»“æœæ±‡æ€» (Result Aggregation)
    â†“
çŠ¶æ€æ›´æ–° (Status Update)
```

### 1.2 æ ¸å¿ƒè®¾è®¡åŸåˆ™

- **åˆ†è€Œæ²»ä¹‹**ï¼šå°†å¤§æ•°æ®é›†åˆ†å‰²æˆå°å—ï¼Œå¹¶è¡Œå¤„ç†
- **è´Ÿè½½å‡è¡¡**ï¼šç¡®ä¿å„ä¸ªå¤„ç†èŠ‚ç‚¹è´Ÿè½½ç›¸å¯¹å‡åŒ€
- **æ•…éšœéš”ç¦»**ï¼šå•ä¸ªåˆ†ç‰‡å¤±è´¥ä¸å½±å“å…¶ä»–åˆ†ç‰‡å¤„ç†
- **èµ„æºæ§åˆ¶**ï¼šåˆç†æ§åˆ¶å¹¶å‘æ•°å’Œå†…å­˜ä½¿ç”¨
- **è¿›åº¦è·Ÿè¸ª**ï¼šå®æ—¶ç›‘æ§å¤„ç†è¿›åº¦å’ŒçŠ¶æ€

## 2. æ•°æ®åˆ†ç‰‡ç­–ç•¥

### 2.1 åŸºäºæ—¶é—´èŒƒå›´çš„åˆ†ç‰‡

```sql
-- æ—¶é—´èŒƒå›´åˆ†ç‰‡ç¤ºä¾‹
-- åˆ†ç‰‡ 1: 2023-01-01 to 2023-01-31
SELECT * FROM orders 
WHERE order_date >= '2023-01-01' AND order_date < '2023-02-01';

-- åˆ†ç‰‡ 2: 2023-02-01 to 2023-02-28  
SELECT * FROM orders
WHERE order_date >= '2023-02-01' AND order_date < '2023-03-01';

-- åˆ†ç‰‡ 3: 2023-03-01 to 2023-03-31
SELECT * FROM orders
WHERE order_date >= '2023-03-01' AND order_date < '2023-04-01';
```

**Kettle å®ç°**ï¼š

```xml
<!-- ç”Ÿæˆæ—¶é—´åˆ†ç‰‡å‚æ•° -->
<step>
    <name>Generate Date Ranges</name>
    <type>DataGrid</type>
    <data>
        <line><item>2023-01-01</item><item>2023-02-01</item><item>1</item></line>
        <line><item>2023-02-01</item><item>2023-03-01</item><item>2</item></line>
        <line><item>2023-03-01</item><item>2023-04-01</item><item>3</item></line>
        <line><item>2023-04-01</item><item>2023-05-01</item><item>4</item></line>
    </data>
    <fields>
        <field><name>start_date</name><type>String</type></field>
        <field><name>end_date</name><type>String</type></field>
        <field><name>shard_id</name><type>Integer</type></field>
    </fields>
</step>
```

### 2.2 åŸºäºä¸»é”®èŒƒå›´çš„åˆ†ç‰‡

```sql
-- ä¸»é”®èŒƒå›´åˆ†ç‰‡
-- å…ˆè·å–æ•°æ®èŒƒå›´
SELECT MIN(id) as min_id, MAX(id) as max_id, COUNT(*) as total_count
FROM orders;

-- è®¡ç®—åˆ†ç‰‡å¤§å°
-- å‡è®¾ min_id=1, max_id=10000000, total_count=10000000, åˆ†æˆ 10 ç‰‡
-- æ¯ç‰‡å¤„ç† 1000000 æ¡è®°å½•

-- åˆ†ç‰‡ 1: ID 1 åˆ° 1000000
SELECT * FROM orders WHERE id BETWEEN 1 AND 1000000;

-- åˆ†ç‰‡ 2: ID 1000001 åˆ° 2000000  
SELECT * FROM orders WHERE id BETWEEN 1000001 AND 2000000;
```

**Kettle åŠ¨æ€åˆ†ç‰‡ç”Ÿæˆ**ï¼š

```javascript
// JavaScript æ­¥éª¤ï¼šè®¡ç®—åˆ†ç‰‡èŒƒå›´
var total_records = parseInt(getVariable("TOTAL_RECORDS"));
var shard_count = parseInt(getVariable("SHARD_COUNT", "8"));
var records_per_shard = Math.ceil(total_records / shard_count);

var min_id = parseInt(getVariable("MIN_ID"));
var max_id = parseInt(getVariable("MAX_ID"));
var id_range = max_id - min_id + 1;
var ids_per_shard = Math.ceil(id_range / shard_count);

// ç”Ÿæˆå½“å‰åˆ†ç‰‡çš„èŒƒå›´
var current_shard = parseInt(getVariable("CURRENT_SHARD", "1"));
var shard_start_id = min_id + (current_shard - 1) * ids_per_shard;
var shard_end_id = Math.min(shard_start_id + ids_per_shard - 1, max_id);

setVariable("SHARD_START_ID", shard_start_id.toString());
setVariable("SHARD_END_ID", shard_end_id.toString());

start_id = shard_start_id;
end_id = shard_end_id;
```

### 2.3 åŸºäº Hash çš„åˆ†ç‰‡

```sql
-- Hash åˆ†ç‰‡ï¼ˆé€‚åˆæ— åºæ•°æ®ï¼‰
-- åˆ†ç‰‡ 1: Hash å€¼ 0-1
SELECT * FROM orders WHERE CRC32(customer_id) % 8 = 0;

-- åˆ†ç‰‡ 2: Hash å€¼ 1-2
SELECT * FROM orders WHERE CRC32(customer_id) % 8 = 1;

-- åˆ†ç‰‡ 3: Hash å€¼ 2-3  
SELECT * FROM orders WHERE CRC32(customer_id) % 8 = 2;
```

**ä¼˜ç¼ºç‚¹å¯¹æ¯”**ï¼š

| åˆ†ç‰‡ç­–ç•¥ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|------|------|----------|
| æ—¶é—´èŒƒå›´ | ç¬¦åˆä¸šåŠ¡é€»è¾‘ï¼Œä¾¿äºåˆ†åŒºå¯¹åº” | å¯èƒ½æ•°æ®å€¾æ–œ | æœ‰æ˜ç¡®æ—¶é—´å­—æ®µçš„å†å²æ•°æ® |
| ä¸»é”®èŒƒå›´ | æ•°æ®åˆ†å¸ƒç›¸å¯¹å‡åŒ€ | éœ€è¦è¿ç»­ä¸»é”® | æœ‰è‡ªå¢ä¸»é”®çš„è¡¨ |
| Hash åˆ†ç‰‡ | æ•°æ®åˆ†å¸ƒæœ€å‡åŒ€ | æ— ä¸šåŠ¡å«ä¹‰ | æ•°æ®åˆ†å¸ƒéšæœºçš„å¤§è¡¨ |

## 3. å¹¶è¡Œå¤„ç†å®ç°

### 3.1 Kettle Job çº§åˆ«å¹¶è¡Œ

```xml
<job>
    <name>Parallel Batch Processing</name>
    
    <!-- åˆå§‹åŒ–å‚æ•° -->
    <entry>
        <name>Initialize Parameters</name>
        <type>EVAL</type>
        <script>
            parent_job.setVariable("PARALLEL_COUNT", "4");
            parent_job.setVariable("BATCH_SIZE", "50000");
            parent_job.setVariable("START_TIME", new Date().toISOString());
        </script>
    </entry>
    
    <!-- å¹¶è¡Œæ‰§è¡Œå¤šä¸ªè½¬æ¢ -->
    <entry>
        <name>Process Shard 1</name>
        <type>TRANS</type>
        <filename>shard_processor.ktr</filename>
        <parameters>
            <parameter><name>SHARD_ID</name><value>1</value></parameter>
            <parameter><name>SHARD_START</name><value>1</value></parameter>
            <parameter><name>SHARD_END</name><value>2500000</value></parameter>
        </parameters>
        <parallel>Y</parallel>
    </entry>
    
    <entry>
        <name>Process Shard 2</name>
        <type>TRANS</type>
        <filename>shard_processor.ktr</filename>
        <parameters>
            <parameter><name>SHARD_ID</name><value>2</value></parameter>
            <parameter><name>SHARD_START</name><value>2500001</value></parameter>
            <parameter><name>SHARD_END</name><value>5000000</value></parameter>
        </parameters>
        <parallel>Y</parallel>
    </entry>
    
    <!-- ç­‰å¾…æ‰€æœ‰åˆ†ç‰‡å®Œæˆ -->
    <entry>
        <name>Wait for All Shards</name>
        <type>DUMMY</type>
    </entry>
    
    <!-- æ±‡æ€»ç»“æœ -->
    <entry>
        <name>Summarize Results</name>
        <type>SQL</type>
        <sql>
            INSERT INTO batch_process_log (
                batch_id, start_time, end_time, 
                total_processed, total_errors, status
            ) VALUES (
                '${BATCH_ID}', '${START_TIME}', NOW(),
                ${TOTAL_PROCESSED}, ${TOTAL_ERRORS}, 'completed'
            )
        </sql>
    </entry>
</job>
```

### 3.2 è½¬æ¢çº§åˆ«å¹¶è¡Œ

```xml
<!-- åœ¨è½¬æ¢ä¸­ä½¿ç”¨å¤šä¸ªå¹¶è¡Œçš„æ­¥éª¤ -->
<transformation>
    <name>shard_processor</name>
    
    <!-- è¯»å–æ•°æ® -->
    <step>
        <name>Read Shard Data</name>
        <type>TableInput</type>
        <sql>
            SELECT * FROM orders 
            WHERE id BETWEEN ${SHARD_START} AND ${SHARD_END}
            ORDER BY id
        </sql>
        <copies>1</copies>
    </step>
    
    <!-- æ•°æ®åˆ†æµåˆ°å¤šä¸ªå¤„ç†ç®¡é“ -->
    <step>
        <name>Distribute Data</name>
        <type>Calculator</type>
        <calculation>
            <field_name>pipeline_id</field_name>
            <calc_type>MOD</calc_type>
            <field_a>id</field_a>
            <field_b>4</field_b>
            <value_type>Integer</value_type>
        </calculation>
        <copies>1</copies>
    </step>
    
    <!-- å¤šä¸ªå¹¶è¡Œå¤„ç†ç®¡é“ -->
    <step>
        <name>Process Pipeline 1</name>
        <type>FilterRows</type>
        <condition>
            <field>pipeline_id</field>
            <function>=</function>
            <value>0</value>
        </condition>
        <copies>2</copies>  <!-- æ¯ä¸ªç®¡é“ 2 ä¸ªå¹¶è¡Œå‰¯æœ¬ -->
    </step>
    
    <step>
        <name>Process Pipeline 2</name>
        <type>FilterRows</type>
        <condition>
            <field>pipeline_id</field>
            <function>=</function>
            <value>1</value>
        </condition>
        <copies>2</copies>
    </step>
    
    <!-- æ•°æ®å†™å…¥ StarRocks -->
    <step>
        <name>Write to StarRocks</name>
        <type>TableOutput</type>
        <table>orders_target</table>
        <commit_size>10000</commit_size>
        <copies>1</copies>  <!-- å†™å…¥ç»Ÿä¸€ä¸²è¡Œ -->
    </step>
</transformation>
```

## 4. èµ„æºç®¡ç†å’Œè´Ÿè½½æ§åˆ¶

### 4.1 å†…å­˜ç®¡ç†ç­–ç•¥

```bash
# JVM å†…å­˜é…ç½®
export PENTAHO_DI_JAVA_OPTIONS="
-Xms4g -Xmx16g                          # å †å†…å­˜
-XX:NewRatio=1                           # æ–°ç”Ÿä»£æ¯”ä¾‹
-XX:+UseG1GC                            # G1 åƒåœ¾æ”¶é›†å™¨
-XX:G1HeapRegionSize=16m                 # G1 åŒºåŸŸå¤§å°
-XX:MaxGCPauseMillis=200                 # æœ€å¤§ GC æš‚åœæ—¶é—´
-XX:+UnlockExperimentalVMOptions         # å¯ç”¨å®éªŒç‰¹æ€§
-XX:+UseCGroupMemoryLimitForHeap         # å®¹å™¨å†…å­˜é™åˆ¶
-Dfile.encoding=UTF-8                    # å­—ç¬¦ç¼–ç 
"

# æ­¥éª¤çº§å†…å­˜æ§åˆ¶
export PDI_STEP_CACHE_SIZE="50000"       # æ­¥éª¤ç¼“å­˜å¤§å°
export PDI_ROW_BUFFER_SIZE="100000"      # è¡Œç¼“å†²å¤§å°
```

### 4.2 è¿æ¥æ± ç®¡ç†

```xml
<!-- æ•°æ®åº“è¿æ¥æ± é…ç½® -->
<connection>
    <name>Source_Pool</name>
    <pooling_enabled>Y</pooling_enabled>
    <initial_pool_size>2</initial_pool_size>
    <maximum_pool_size>10</maximum_pool_size>
    <connection_test_query>SELECT 1</connection_test_query>
    <idle_test_period>300</idle_test_period>
    <test_on_borrow>Y</test_on_borrow>
    <test_on_return>N</test_on_return>
    <test_while_idle>Y</test_while_idle>
</connection>

<connection>
    <name>StarRocks_Pool</name>
    <pooling_enabled>Y</pooling_enabled>
    <initial_pool_size>4</initial_pool_size>
    <maximum_pool_size>20</maximum_pool_size>
    <connection_test_query>SELECT 1</connection_test_query>
</connection>
```

### 4.3 æµé‡æ§åˆ¶æœºåˆ¶

```javascript
// åŠ¨æ€è°ƒæ•´å¹¶è¡Œåº¦
var current_cpu_usage = getCpuUsage();  // è‡ªå®šä¹‰å‡½æ•°è·å– CPU ä½¿ç”¨ç‡
var current_memory_usage = getMemoryUsage();  // è‡ªå®šä¹‰å‡½æ•°è·å–å†…å­˜ä½¿ç”¨ç‡

var parallel_count = parseInt(getVariable("PARALLEL_COUNT", "4"));

// æ ¹æ®èµ„æºä½¿ç”¨æƒ…å†µè°ƒæ•´å¹¶è¡Œåº¦
if (current_cpu_usage > 85 || current_memory_usage > 80) {
    // èµ„æºç´§å¼ ï¼Œå‡å°‘å¹¶è¡Œåº¦
    parallel_count = Math.max(parallel_count - 1, 1);
    writeToLog("w", "èµ„æºä½¿ç”¨ç‡è¾ƒé«˜ï¼Œé™ä½å¹¶è¡Œåº¦è‡³: " + parallel_count);
} else if (current_cpu_usage < 50 && current_memory_usage < 60) {
    // èµ„æºå……è¶³ï¼Œå¯ä»¥å¢åŠ å¹¶è¡Œåº¦
    parallel_count = Math.min(parallel_count + 1, 8);
    writeToLog("i", "èµ„æºä½¿ç”¨ç‡è¾ƒä½ï¼Œæå‡å¹¶è¡Œåº¦è‡³: " + parallel_count);
}

setVariable("PARALLEL_COUNT", parallel_count.toString());

// åŠ¨æ€è°ƒæ•´æ‰¹é‡å¤§å°
var current_batch_size = parseInt(getVariable("BATCH_SIZE", "10000"));
var last_process_time = parseInt(getVariable("LAST_PROCESS_TIME", "0"));

if (last_process_time > 300000) {  // è¶…è¿‡ 5 åˆ†é’Ÿ
    current_batch_size = Math.max(current_batch_size * 0.8, 1000);
} else if (last_process_time < 60000) {  // å°äº 1 åˆ†é’Ÿ
    current_batch_size = Math.min(current_batch_size * 1.2, 100000);
}

setVariable("BATCH_SIZE", current_batch_size.toString());
```

## 5. é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

### 5.1 åˆ†ç‰‡çº§é”™è¯¯éš”ç¦»

```xml
<job>
    <name>Resilient Batch Processing</name>
    
    <!-- è®°å½•å¼€å§‹çŠ¶æ€ -->
    <entry>
        <name>Record Start Status</name>
        <type>SQL</type>
        <sql>
            INSERT INTO shard_status (shard_id, status, start_time)
            VALUES (${SHARD_ID}, 'running', NOW())
            ON DUPLICATE KEY UPDATE status = 'running', start_time = NOW()
        </sql>
    </entry>
    
    <!-- æ‰§è¡Œåˆ†ç‰‡å¤„ç† -->
    <entry>
        <name>Process Shard</name>
        <type>TRANS</type>
        <filename>shard_processor.ktr</filename>
        <on_error>Handle Shard Error</on_error>
    </entry>
    
    <!-- æˆåŠŸå¤„ç† -->
    <entry>
        <name>Record Success</name>
        <type>SQL</type>
        <sql>
            UPDATE shard_status 
            SET status = 'completed', 
                end_time = NOW(),
                processed_rows = ${PROCESSED_ROWS}
            WHERE shard_id = ${SHARD_ID}
        </sql>
    </entry>
    
    <!-- é”™è¯¯å¤„ç† -->
    <entry>
        <name>Handle Shard Error</name>
        <type>SQL</type>
        <sql>
            UPDATE shard_status 
            SET status = 'failed',
                end_time = NOW(),
                error_message = '${ERROR_MESSAGE}'
            WHERE shard_id = ${SHARD_ID}
        </sql>
        <on_success>Notify Error</on_success>
    </entry>
    
    <!-- é”™è¯¯é€šçŸ¥ -->
    <entry>
        <name>Notify Error</name>
        <type>MAIL</type>
        <server>smtp_server</server>
        <subject>æ‰¹å¤„ç†åˆ†ç‰‡ ${SHARD_ID} å¤±è´¥</subject>
        <message>åˆ†ç‰‡ ${SHARD_ID} å¤„ç†å¤±è´¥: ${ERROR_MESSAGE}</message>
    </entry>
</job>
```

### 5.2 æ™ºèƒ½é‡è¯•ç­–ç•¥

```javascript
// æŒ‡æ•°é€€é¿é‡è¯•ç®—æ³•
function calculateRetryDelay(retryCount, baseDelayMs, maxDelayMs) {
    var delay = baseDelayMs * Math.pow(2, retryCount);
    return Math.min(delay, maxDelayMs);
}

var retry_count = parseInt(getVariable("RETRY_COUNT", "0"));
var max_retries = parseInt(getVariable("MAX_RETRIES", "3"));
var base_delay = 5000; // 5 ç§’åŸºç¡€å»¶è¿Ÿ
var max_delay = 300000; // æœ€å¤§ 5 åˆ†é’Ÿå»¶è¿Ÿ

if (retry_count < max_retries) {
    var delay_ms = calculateRetryDelay(retry_count, base_delay, max_delay);
    
    writeToLog("w", "ç¬¬ " + (retry_count + 1) + " æ¬¡é‡è¯•ï¼Œå»¶è¿Ÿ " + (delay_ms / 1000) + " ç§’");
    
    // ç­‰å¾…æŒ‡å®šæ—¶é—´
    java.lang.Thread.sleep(delay_ms);
    
    setVariable("RETRY_COUNT", (retry_count + 1).toString());
    should_retry = true;
} else {
    writeToLog("e", "è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œåœæ­¢é‡è¯•");
    should_retry = false;
}
```

### 5.3 æ–­ç‚¹ç»­ä¼ æœºåˆ¶

```sql
-- åˆ›å»ºå¤„ç†çŠ¶æ€è¡¨
CREATE TABLE batch_progress (
    batch_id VARCHAR(64),
    shard_id INT,
    start_id BIGINT,
    end_id BIGINT,
    last_processed_id BIGINT,
    processed_rows BIGINT,
    status ENUM('pending', 'running', 'completed', 'failed'),
    start_time DATETIME,
    end_time DATETIME,
    error_message TEXT,
    PRIMARY KEY (batch_id, shard_id)
);
```

```javascript
// æ–­ç‚¹ç»­ä¼ é€»è¾‘
var batch_id = getVariable("BATCH_ID");
var shard_id = parseInt(getVariable("SHARD_ID"));

// æŸ¥è¯¢ä¸Šæ¬¡å¤„ç†è¿›åº¦
var last_processed_id = getVariableFromDB(
    "SELECT last_processed_id FROM batch_progress WHERE batch_id = '" + batch_id + 
    "' AND shard_id = " + shard_id
);

var original_start_id = parseInt(getVariable("SHARD_START_ID"));
var start_id = last_processed_id ? Math.max(last_processed_id + 1, original_start_id) : original_start_id;

setVariable("EFFECTIVE_START_ID", start_id.toString());

if (last_processed_id && last_processed_id > original_start_id) {
    writeToLog("i", "ä»æ–­ç‚¹ ID " + start_id + " ç»§ç»­å¤„ç†åˆ†ç‰‡ " + shard_id);
} else {
    writeToLog("i", "å¼€å§‹å¤„ç†åˆ†ç‰‡ " + shard_id + "ï¼Œèµ·å§‹ ID " + start_id);
}
```

## 6. æ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜

### 6.1 å®æ—¶æ€§èƒ½ç›‘æ§

```javascript
// æ€§èƒ½æŒ‡æ ‡æ”¶é›†
var start_time = new Date().getTime();

// ... æ•°æ®å¤„ç†é€»è¾‘ ...

var end_time = new Date().getTime();
var process_time_ms = end_time - start_time;
var processed_rows = parseInt(getVariable("PROCESSED_ROWS", "0"));

// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
var rows_per_second = processed_rows / (process_time_ms / 1000);
var memory_usage = getMemoryUsage();  // MB
var cpu_usage = getCpuUsage();        // %

// è®°å½•æ€§èƒ½æŒ‡æ ‡åˆ°ç›‘æ§è¡¨
var sql = "INSERT INTO performance_metrics (" +
    "batch_id, shard_id, timestamp, process_time_ms, processed_rows, " +
    "rows_per_second, memory_usage_mb, cpu_usage_percent" +
    ") VALUES (" +
    "'" + getVariable("BATCH_ID") + "', " +
    getVariable("SHARD_ID") + ", " +
    "NOW(), " + process_time_ms + ", " + processed_rows + ", " +
    rows_per_second.toFixed(2) + ", " + memory_usage + ", " + cpu_usage +
    ")";

executeSQL(sql);

// è¾“å‡ºæ€§èƒ½æ‘˜è¦
writeToLog("i", "åˆ†ç‰‡ " + getVariable("SHARD_ID") + " æ€§èƒ½æŒ‡æ ‡:");
writeToLog("i", "  - å¤„ç†æ—¶é—´: " + (process_time_ms / 1000).toFixed(2) + " ç§’");
writeToLog("i", "  - å¤„ç†è¡Œæ•°: " + processed_rows);
writeToLog("i", "  - å¤„ç†é€Ÿç‡: " + rows_per_second.toFixed(0) + " è¡Œ/ç§’");
writeToLog("i", "  - å†…å­˜ä½¿ç”¨: " + memory_usage + " MB");
writeToLog("i", "  - CPU ä½¿ç”¨: " + cpu_usage + "%");
```

### 6.2 ç“¶é¢ˆè¯†åˆ«å’Œè°ƒä¼˜

```bash
#!/bin/bash
# performance_analyzer.sh

LOG_FILE="/path/to/batch_process.log"
PERF_LOG="/path/to/performance.log"

echo "=== æ‰¹å¤„ç†æ€§èƒ½åˆ†ææŠ¥å‘Š ===" > "$PERF_LOG"
echo "ç”Ÿæˆæ—¶é—´: $(date)" >> "$PERF_LOG"
echo "" >> "$PERF_LOG"

# åˆ†æå¤„ç†é€Ÿç‡
echo "=== å¤„ç†é€Ÿç‡åˆ†æ ===" >> "$PERF_LOG"
grep "å¤„ç†é€Ÿç‡:" "$LOG_FILE" | tail -20 | \
awk -F: '{print $NF}' | awk '{print $1}' | \
awk '{sum+=$1; count++} END {
    if(count>0) {
        avg=sum/count;
        print "å¹³å‡å¤„ç†é€Ÿç‡: " avg " è¡Œ/ç§’"
        if(avg < 1000) print "âš ï¸  å¤„ç†é€Ÿç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥ SQL ä¼˜åŒ–å’Œç´¢å¼•"
        else if(avg > 10000) print "âœ… å¤„ç†é€Ÿç‡è‰¯å¥½"
        else print "â„¹ï¸  å¤„ç†é€Ÿç‡ä¸­ç­‰"
    }
}' >> "$PERF_LOG"

# åˆ†æå†…å­˜ä½¿ç”¨
echo "" >> "$PERF_LOG"
echo "=== å†…å­˜ä½¿ç”¨åˆ†æ ===" >> "$PERF_LOG"
grep "å†…å­˜ä½¿ç”¨:" "$LOG_FILE" | tail -20 | \
awk -F: '{print $NF}' | awk '{print $1}' | \
awk '{sum+=$1; count++; if($1>max) max=$1} END {
    if(count>0) {
        avg=sum/count;
        print "å¹³å‡å†…å­˜ä½¿ç”¨: " avg " MB"
        print "å³°å€¼å†…å­˜ä½¿ç”¨: " max " MB"
        if(max > 8192) print "âš ï¸  å†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œå»ºè®®è°ƒæ•´ JVM å‚æ•°æˆ–å‡å°‘æ‰¹é‡å¤§å°"
        else print "âœ… å†…å­˜ä½¿ç”¨æ­£å¸¸"
    }
}' >> "$PERF_LOG"

# åˆ†æé”™è¯¯ç‡
echo "" >> "$PERF_LOG"
echo "=== é”™è¯¯ç‡åˆ†æ ===" >> "$PERF_LOG"
TOTAL_BATCHES=$(grep -c "åˆ†ç‰‡.*å¼€å§‹å¤„ç†\|åˆ†ç‰‡.*å¤„ç†å®Œæˆ\|åˆ†ç‰‡.*å¤„ç†å¤±è´¥" "$LOG_FILE")
ERROR_BATCHES=$(grep -c "åˆ†ç‰‡.*å¤„ç†å¤±è´¥" "$LOG_FILE")

if [ "$TOTAL_BATCHES" -gt 0 ]; then
    ERROR_RATE=$(echo "scale=2; $ERROR_BATCHES * 100 / $TOTAL_BATCHES" | bc)
    echo "æ€»å¤„ç†æ‰¹æ¬¡: $TOTAL_BATCHES" >> "$PERF_LOG"
    echo "å¤±è´¥æ‰¹æ¬¡: $ERROR_BATCHES" >> "$PERF_LOG"
    echo "é”™è¯¯ç‡: $ERROR_RATE%" >> "$PERF_LOG"
    
    if (( $(echo "$ERROR_RATE > 5" | bc -l) )); then
        echo "âš ï¸  é”™è¯¯ç‡è¾ƒé«˜ï¼Œéœ€è¦æ£€æŸ¥é”™è¯¯æ—¥å¿—" >> "$PERF_LOG"
    else
        echo "âœ… é”™è¯¯ç‡åœ¨å¯æ¥å—èŒƒå›´å†…" >> "$PERF_LOG"
    fi
fi

echo "" >> "$PERF_LOG"
echo "è¯¦ç»†æŠ¥å‘Šå·²ç”Ÿæˆ: $PERF_LOG"
```

## 7. æœ€ä½³å®è·µæ€»ç»“

### 7.1 åˆ†ç‰‡ç­–ç•¥é€‰æ‹©
- **å†å²æ•°æ®è¿ç§»**ï¼šä¼˜å…ˆä½¿ç”¨æ—¶é—´èŒƒå›´åˆ†ç‰‡ï¼Œä¸ StarRocks åˆ†åŒºç­–ç•¥å¯¹åº”
- **å¤§è¡¨å…¨é‡åŒæ­¥**ï¼šä½¿ç”¨ä¸»é”®èŒƒå›´åˆ†ç‰‡ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§
- **å®æ—¶æ•°æ®å¤„ç†**ï¼šä½¿ç”¨ Hash åˆ†ç‰‡ï¼Œä¿è¯è´Ÿè½½å‡è¡¡

### 7.2 å¹¶è¡Œåº¦è®¾ç½®
- **CPU å¯†é›†å‹**ï¼šå¹¶è¡Œåº¦ = CPU æ ¸å¿ƒæ•°
- **I/O å¯†é›†å‹**ï¼šå¹¶è¡Œåº¦ = CPU æ ¸å¿ƒæ•° Ã— 2
- **å†…å­˜å—é™å‹**ï¼šæ ¹æ®å¯ç”¨å†…å­˜åŠ¨æ€è°ƒæ•´

### 7.3 èµ„æºç®¡ç†è¦ç‚¹
- è®¾ç½®åˆç†çš„ JVM å †å†…å­˜ï¼Œé€šå¸¸ä¸ºç³»ç»Ÿå†…å­˜çš„ 60-70%
- ä½¿ç”¨è¿æ¥æ± é¿å…é¢‘ç¹åˆ›å»ºæ•°æ®åº“è¿æ¥
- å®æ–½æµé‡æ§åˆ¶ï¼Œé˜²æ­¢ç³»ç»Ÿè¿‡è½½
- å®šæœŸç›‘æ§å’Œæ¸…ç†ä¸´æ—¶æ–‡ä»¶

### 7.4 é”™è¯¯å¤„ç†ç­–ç•¥
- å®ç°åˆ†ç‰‡çº§é”™è¯¯éš”ç¦»ï¼Œå•ä¸ªåˆ†ç‰‡å¤±è´¥ä¸å½±å“æ•´ä½“
- é‡‡ç”¨æŒ‡æ•°é€€é¿é‡è¯•ç­–ç•¥ï¼Œé¿å…é›ªå´©æ•ˆåº”
- æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œæé«˜å¤„ç†æ•ˆç‡
- å»ºç«‹å®Œå–„çš„ç›‘æ§å‘Šè­¦æœºåˆ¶

### 7.5 æ€§èƒ½è°ƒä¼˜å»ºè®®
- å®šæœŸåˆ†ææ€§èƒ½æŒ‡æ ‡ï¼Œè¯†åˆ«ç“¶é¢ˆç‚¹
- ä¼˜åŒ– SQL æŸ¥è¯¢ï¼Œä½¿ç”¨åˆé€‚çš„ç´¢å¼•
- è°ƒæ•´æ‰¹é‡å¤§å°ï¼Œå¹³è¡¡å†…å­˜ä½¿ç”¨å’Œå¤„ç†æ•ˆç‡
- ä½¿ç”¨ Stream Load æ›¿ä»£ INSERT æå‡å†™å…¥æ€§èƒ½

é€šè¿‡åˆç†çš„æ‰¹é‡å¤„ç†ç­–ç•¥ï¼Œå¯ä»¥æ˜¾è‘—æå‡å¤§æ•°æ®é‡çš„ ETL å¤„ç†æ•ˆç‡å’Œç³»ç»Ÿç¨³å®šæ€§ã€‚

---
## ğŸ“– å¯¼èˆª
[ğŸ  è¿”å›ä¸»é¡µ](../../README.md) | [â¬…ï¸ ä¸Šä¸€é¡µ](modern-etl-tools.md) | [â¡ï¸ ä¸‹ä¸€é¡µ](error-handling-mechanisms.md)
---